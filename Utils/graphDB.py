import os
import json
import time
from dotenv import load_dotenv
from langchain_experimental.graph_transformers import LLMGraphTransformer
from langchain_groq import ChatGroq
from langchain.docstore.document import Document
from langchain_neo4j import Neo4jGraph
from typing import List

load_dotenv()

GROQ_API_KEY = os.getenv("GROQ_API_KEY")
if not GROQ_API_KEY:
    raise RuntimeError("GROQ_API_KEY not set")

llm = ChatGroq(model_name="qwen/qwen3-32b", temperature=0.7, api_key=GROQ_API_KEY)
transformer = LLMGraphTransformer(llm=llm)


def load_docs(filepath: str) -> List[Document]:
    print("âŒ› Loading chunks from", filepath)
    with open(filepath, "r", encoding="utf-8") as f:
        arr = json.load(f)
    return [Document(page_content=d["page_content"], metadata=d["metadata"]) for d in arr]

all_docs = load_docs("all_docs.json")
print(f"ğŸ“„ Loaded {len(all_docs)} pre-chunked documents")

graph = Neo4jGraph(
    url="bolt+ssc://933bd554.databases.neo4j.io:7687",
    username="neo4j",
    password="CMy8sjFM9grBNaz0R4uPWvMznKb8ECad-buNINUPcbs",
    database="neo4j",
)

print("âœ… Connected to Neo4j Aura")

start = time.time()
for idx, doc in enumerate(all_docs[825:], 825):
    print(f"[{idx}/{len(all_docs)}] Converting â†’ GraphDocumentâ€¦", end="\r")
    try:
        gd = transformer.convert_to_graph_documents([doc])[0]
    except Exception as e:
        print(f"\nâš ï¸ Error on chunk {idx}: {e!r} â€” retryingâ€¦")
        gd = transformer.convert_to_graph_documents([doc])[0]

    graph.add_graph_documents(
        graph_documents=[gd],
        include_source=True,
        baseEntityLabel=True,
    )

print(f"\nğŸ Done! Total time: {time.time() - start:.1f}s")
